"""Shared helpers and types for lesson AI nodes."""

import json
import logging
import re
from typing import Any, Dict, List, Optional, TypedDict, cast

from django.conf import settings
from langchain_google_genai import ChatGoogleGenerativeAI

logger = logging.getLogger(__name__)

# --- Constants ---
MAX_HISTORY_TURNS = 10

# --- Helper Functions ---

def _truncate_history(history: List[Dict[str, str]]) -> List[Dict[str, str]]:
    """Truncates conversation history."""
    return history[-MAX_HISTORY_TURNS:]

def _format_history_for_prompt(history: List[Dict[str, str]]) -> str:
    """Formats conversation history for prompts."""
    formatted = []
    for msg in history:
        role = msg.get("role", "unknown")
        content = msg.get("content", "")
        formatted.append(f"{role.capitalize()}: {content}")
    return "\n".join(formatted)

def _get_llm(temperature: float = 0.2) -> Optional[ChatGoogleGenerativeAI]:
    """Initializes and returns the LangChain LLM model."""
    api_key = settings.GEMINI_API_KEY
    model_name = settings.FAST_MODEL
    if not api_key or not model_name:
        logger.error("LLM API key or model name not configured in settings.")
        return None
    try:
        llm = ChatGoogleGenerativeAI(
            model=model_name,
            google_api_key=api_key,
            temperature=temperature,
            convert_system_message_to_human=True,
        )  # type: ignore[call-arg]
        logger.info(
            f"Successfully initialized LLM. Model: {model_name}"
        )
        return llm
    except Exception as e:
        logger.error(
            "Failed to initialize ChatGoogleGenerativeAI: %s", e, exc_info=True
        )
        return None

def _parse_llm_json_response(response: Any) -> Optional[Dict[str, Any]]:
    """Attempts to parse a JSON object from the LLM response text."""
    json_str = None
    try:
        # Handle both string responses and response objects with a 'content' or 'text' attribute
        if isinstance(response, str):
            response_text = response
        elif hasattr(response, "content") and isinstance(response.content, str):
            response_text = response.content
        elif hasattr(response, "text") and isinstance(response.text, str):
            response_text = response.text
        else:
            logger.error(f"Unexpected response type for JSON parsing: {type(response)}")
            return None

        # Try to find JSON within markdown code blocks first
        match = re.search(r"```(?:json)?\s*({.*?})\s*```", response_text, re.DOTALL)
        if match:
            json_str = match.group(1)
            logger.info("Found JSON within markdown block.")
        else:
            # If no markdown block, assume the whole text is JSON (after stripping)
            json_str = response_text.strip()
            # Basic check if it looks like JSON before attempting parse
            if not (json_str.startswith("{") and json_str.endswith("}")):
                logger.warning("Response does not appear to be JSON or markdown block.")
                return None
            logger.info("Attempting to parse response text directly as JSON.")

        # Clean up common escape issues before parsing
        json_str = re.sub(r"\\n", "", json_str)  # Remove escaped newlines
        json_str = re.sub(
            r"\\(?![\"\\/bfnrtu])", "", json_str
        )  # Remove invalid escapes

        # Parse the extracted JSON string
        parsed_json = json.loads(json_str)
        if not isinstance(parsed_json, dict):
            logger.warning(f"Parsed JSON is not a dictionary: {type(parsed_json)}")
            return None

        logger.info("Successfully parsed JSON from LLM response.")
        return parsed_json

    except json.JSONDecodeError as e:
        logger.error(
            f"Failed to parse JSON from response: {e}. String was: {json_str}..."
        )
        return None
    except Exception as e:
        logger.error(f"Unexpected error during JSON parsing: {e}", exc_info=True)
        return None

# --- Data Structures (TypedDicts) ---

class IntentClassificationResult(TypedDict, total=False):
    """Represents the result of intent classification with optional reasoning."""
    intent: str
    reasoning: Optional[str]

class ExerciseOption(TypedDict, total=False):
    """Represents an option for a multiple-choice exercise."""
    id: str
    text: str

class ExerciseMisconception(TypedDict, total=False):
    """Represents misconceptions and corrections related to an exercise."""

class Exercise(TypedDict, total=False):
    """Represents an exercise generated by the AI, including question, options, and metadata."""
    id: str
    type: str
    question: Optional[str]
    instructions: str
    items: Optional[List[str]]
    options: Optional[List[ExerciseOption]]
    correct_answer_id: Optional[str]
    expected_solution_format: Optional[str]
    correct_answer: Optional[str]
    hints: Optional[List[str]]
    explanation: str
    misconception_corrections: Optional[ExerciseMisconception]

class EvaluationResult(TypedDict, total=False):
    """Represents the result of evaluating a user's answer."""
    score: float
    is_correct: bool
    feedback: str
    explanation: Optional[str]

class AssessmentOption(TypedDict, total=False):
    """Represents an option for an assessment question."""
    id: str
    text: str

class AssessmentQuestion(TypedDict, total=False):
    """Represents an assessment question generated by the AI."""
    id: str
    type: str  # e.g., "multiple_choice", "true_false", "short_answer"
    question_text: str
    options: Optional[List[AssessmentOption]]  # For multiple_choice / true_false
    correct_answer_id: Optional[str]  # For multiple_choice / true_false
    correct_answer: Optional[str]  # For short_answer
    explanation: str
    confidence_check: Optional[bool]  # Default false